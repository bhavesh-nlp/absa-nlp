{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28519c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  01_data_loading_and_cleanup.ipynb\n",
    "\n",
    "# 1. Environment setup\n",
    "# (install requirements first using terminal)\n",
    "\n",
    "# 2. Imports\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "from src.config import RAW_DIR, PROCESSED_DIR\n",
    "\n",
    "# 3. Add project root to Python path\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root added:\", PROJECT_ROOT)\n",
    "\n",
    "\n",
    "# 4. Data loader function for SemEval XML\n",
    "\n",
    "def load_semeval(path):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for s in root.iter('sentence'):\n",
    "        sid = s.attrib.get(\"id\")\n",
    "        text = s.find(\"text\").text if s.find(\"text\") is not None else \"\"\n",
    "\n",
    "        aspects = []\n",
    "\n",
    "        # aspectTerms\n",
    "        at = s.find(\"aspectTerms\")\n",
    "        if at is not None:\n",
    "            for term in at.findall(\"aspectTerm\"):\n",
    "                aspects.append({\n",
    "                    \"type\": \"term\",\n",
    "                    \"term\": term.attrib.get(\"term\"),\n",
    "                    \"polarity\": term.attrib.get(\"polarity\")\n",
    "                })\n",
    "\n",
    "        # aspectCategories\n",
    "        ac = s.find(\"aspectCategories\")\n",
    "        if ac is not None:\n",
    "            for cat in ac.findall(\"aspectCategory\"):\n",
    "                aspects.append({\n",
    "                    \"type\": \"category\",\n",
    "                    \"category\": cat.attrib.get(\"category\"),\n",
    "                    \"polarity\": cat.attrib.get(\"polarity\")\n",
    "                })\n",
    "\n",
    "        data.append({\n",
    "            \"id\": sid,\n",
    "            \"sentence\": text,\n",
    "            \"aspects\": aspects\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# 5. Example: load dataset\n",
    "semeval_path = RAW_DIR / 'Restaurants_Train.xml'\n",
    "if semeval_path.exists():\n",
    "    df = load_semeval(semeval_path)\n",
    "else:\n",
    "    # If file not present, create an empty DataFrame template\n",
    "    df = pd.DataFrame(columns=['id', 'sentence', 'aspects'])\n",
    "    print(f\"Warning: {semeval_path} not found. Edit RAW_DIR and add file.\")\n",
    "\n",
    "# 6. Quick inspection\n",
    "print('Total sentences:', len(df))\n",
    "if len(df) > 0:\n",
    "    display(df.head())\n",
    "\n",
    "# 7. Basic validation \n",
    "\n",
    "def count_aspect_stats(df):\n",
    "    total_sent = len(df)\n",
    "    total_with_aspect = df['aspects'].apply(lambda x: len(x) if isinstance(x, list) else 0).sum()\n",
    "    num_sent_with = (df['aspects'].apply(lambda x: len(x) if isinstance(x, list) else 0) > 0).sum()\n",
    "    return {'total_sentences': total_sent, 'aspect_mentions': total_with_aspect, 'sentences_with_aspects': num_sent_with}\n",
    "\n",
    "print(count_aspect_stats(df))\n",
    "\n",
    "# 8. Save a copy of raw and a lightweight CSV for quick use\n",
    "raw_out = RAW_DIR / 'semeval_loaded_raw.parquet'\n",
    "proc_out = PROCESSED_DIR / 'semeval_sentences.csv'\n",
    "\n",
    "if len(df) > 0:\n",
    "    df.to_parquet(raw_out, index=False)\n",
    "    # Save a small CSV with aspects as string for quick preview\n",
    "    df_preview = df.copy()\n",
    "    df_preview['aspects_str'] = df_preview['aspects'].apply(lambda x: str(x))\n",
    "    df_preview[['id','sentence','aspects_str']].to_csv(proc_out, index=False)\n",
    "    print('Saved raw parquet ->', raw_out)\n",
    "    print('Saved preview csv ->', proc_out)\n",
    "\n",
    "# 9. Basic cleaning utilities\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def fix_whitespace(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def normalize_elongation(text):\n",
    "    # Reduce characters repeated more than twice: \"soooo\" → \"soo\"\n",
    "    return re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n",
    "\n",
    "def normalize_punctuation(text):\n",
    "    # Reduce repeated punctuation: \"!!!\" → \"!!\"\n",
    "    return re.sub(r\"([!?.,])\\1{1,}\", r\"\\1\\1\", text)\n",
    "\n",
    "def clean_spelling_simple(text):\n",
    "    corrections = {\n",
    "        \"personaly\": \"personally\",\n",
    "        \"definately\": \"definitely\",\n",
    "        \"amazng\": \"amazing\",\n",
    "        \"restarant\": \"restaurant\"\n",
    "    }\n",
    "    for wrong, right in corrections.items():\n",
    "        text = re.sub(rf\"\\b{wrong}\\b\", right, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = normalize_unicode(text)\n",
    "    text = fix_whitespace(text)\n",
    "    text = normalize_elongation(text)\n",
    "    text = normalize_punctuation(text)\n",
    "    text = clean_spelling_simple(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply cleaning to a new column\n",
    "if len(df) > 0:\n",
    "    df['sentence_clean'] = df['sentence'].apply(clean_text)\n",
    "    display(df[['id','sentence','sentence_clean']].head())\n",
    "\n",
    "# Save processed df\n",
    "if len(df) > 0:\n",
    "    df.to_parquet(PROCESSED_DIR / 'semeval_processed.parquet', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b14b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c084f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
